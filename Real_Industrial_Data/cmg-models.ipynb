{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport sys\nfrom tqdm import tqdm\nfrom time import time\nimport shutil","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_progress(history):\n    loss_tr = []\n    loss_vl = []\n    acc_tr = []\n    acc_vl = []\n    loss_tr.append(history.history['loss'])\n    loss_vl.append(history.history['val_loss'])\n    acc_tr.append(history.history['categorical_accuracy'])\n    acc_vl.append(history.history['val_categorical_accuracy'])\n    \n    plt.plot(acc_tr[0])\n    plt.plot(acc_vl[0])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()\n\n    plt.plot(loss_tr[0])\n    plt.plot(loss_vl[0])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report,multilabel_confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception1 = 0\ndef report(model):\n    prediction = model.predict(test_gen)\n    if model == inception1:\n        print('incept')\n        prediction = prediction[0]\n    predicted_labels = np.argmax(prediction, axis=1)\n    confusion_mat = multilabel_confusion_matrix(test_gen.labels, predicted_labels, labels=[0,1,2])\n    print(confusion_mat)\n    print(classification_report(test_gen.labels, predicted_labels, labels=[0,1,2], target_names=['faulty','normal','vfaulty'], digits=4))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = 'Image_Data/train_dir'\nval_path = 'Image_Data/eval_dir'\ntest_path = 'Image_Data/test_dir'\n\nnum_train_samples = 14400\nnum_test_samples = 3600\nnum_val_samples = 6000\ntrain_batch_size = 8\nval_batch_size = 8\n\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 256\ndef preprocess(img):\n    img = img[len(img[0])//2:,:]\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n    return img\n\ndatagen = ImageDataGenerator(preprocessing_function=lambda img: preprocess(img),\n                             rescale=1.0/255)\n\ntrain_gen = datagen.flow_from_directory(train_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=train_batch_size,\n                                        class_mode='categorical')\n\nval_gen = datagen.flow_from_directory(val_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=val_batch_size,\n                                        class_mode='categorical')\n\ntest_gen = datagen.flow_from_directory(test_path,\n                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n                                        batch_size=1,\n                                        class_mode='categorical',\n                                        shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DL Models","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, DepthwiseConv2D, BatchNormalization, Flatten, Dense, Dropout\nfrom tensorflow.keras import Model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Metrics\ncat_acc = tf.keras.metrics.CategoricalAccuracy()\nauc_roc = tf.keras.metrics.AUC(multi_label=True, num_labels=3)\nauc_pr = tf.keras.metrics.AUC(curve='PR', multi_label=True, num_labels=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AlexNet","metadata":{}},{"cell_type":"code","source":"def AlexNet(input_shape):\n    input = Input(shape=input_shape)\n    \n    x = Conv2D(96, (11, 11), strides=(4, 4), activation='relu')(input)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(x)\n    \n    x = Conv2D(256, kernel_size=5, padding='same', activation='relu')(x)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(x)\n    \n    x = Conv2D(384, kernel_size=3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.SpatialDropout2D(0.5)(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(384, kernel_size=3, padding='same', activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, kernel_size=3, padding='same', activation='relu')(x)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = BatchNormalization()(x)\n    \n    x = MaxPool2D(pool_size=(3, 3), strides=(2, 2))(x)\n    \n    x = Flatten()(x)\n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(3, activation='softmax')(x)\n    \n    model = Model(inputs=input, outputs=output, name='AlexNet')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alexnet = AlexNet(input_shape=(256,256,3))\nalexnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alexnet.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nalexnet_hist = alexnet.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=50, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'50 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(alexnet_hist.history)\nhist_json_file = 'AlexNet_10ep_history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alexnet.save_weights('AlexNet.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alexnet.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(alexnet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG","metadata":{}},{"cell_type":"code","source":"def conv_2(x,filters,kernel_size,activation):\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n    return x\n\ndef conv_3(x,filters,kernel_size,activation):\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n    return x\n\ndef conv_4(x,filters,kernel_size,activation):\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = Conv2D(filters, kernel_size=kernel_size, padding='same', activation=activation)(x)\n    x = MaxPool2D(pool_size=2, strides=2, padding='same')(x)\n    return x\n\ndef FC(x,units,activation):\n    x = Flatten()(x) \n    x = Dense(units = units, activation =activation)(x)\n    x = Dropout(0.5)(x)\n    x = Dense(units = units, activation =activation)(x)\n    x = Dropout(0.5)(x)\n    x = Dense(units = 3, activation ='softmax')(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG16","metadata":{}},{"cell_type":"code","source":"def VGG16(input_shape):\n    \n    input = Input(shape=input_shape)\n    \n    filters = 64\n    kernel_same = 3\n    act = 'relu'\n    \n    x = conv_2(input,filters,kernel_same,act)\n    x = conv_2(x,filters*2,kernel_same,act)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = conv_3(x,filters*4,kernel_same,act)\n    x = conv_3(x,filters*8,kernel_same,act)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = conv_3(x,filters*8,kernel_same,act)\n    \n    units = 4096\n    \n    output = FC(x,units,act)\n    \n    model = Model(inputs=input, outputs=output, name='VGG16')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(input_shape=(256,256,3))\nvgg16.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nvgg16_hist = vgg16.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(vgg16_hist.history)\nhist_json_file = 'VGG16_10ep_history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(vgg16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### VGG19","metadata":{}},{"cell_type":"code","source":"def VGG19(input_shape):\n    \n    input = Input(shape=input_shape)\n    \n    filters = 64\n    kernel_same = 3\n    act = 'relu'\n    \n    x = conv_2(input,filters,kernel_same,act)\n    x = conv_2(x,filters*2,kernel_same,act)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = conv_4(x,filters*4,kernel_same,act)\n    x = tf.keras.layers.SpatialDropout2D(0.5)(x)\n    x = conv_4(x,filters*8,kernel_same,act)\n    x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n    x = conv_4(x,filters*8,kernel_same,act)\n    \n    units = 4096\n    \n    output = FC(x,units,act)\n    \n    model = Model(inputs=input, outputs=output)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19 = VGG19(input_shape=(256,256,3))\nvgg19.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg19.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nvgg19_hist = vgg19.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(vgg19_hist.history)\nhist_json_file = 'VGG19_10ep_history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = vgg19.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(vgg19)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MobileNet","metadata":{}},{"cell_type":"code","source":"def block(x, filters, strides, activation):\n    \n    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(activation)(x)\n    \n    x = Conv2D(filters=filters, kernel_size=1, strides=1)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(activation)(x)\n    \n    return x\n\ndef MobileNet(input_shape):\n    \n    activation = 'relu'\n    filters = 32\n    reps = 5\n    input = Input(shape =input_shape)\n    x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same')(input)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(activation)(x)\n    \n    x = block(x, filters = filters, strides = 1, activation=activation)\n    x = block(x, filters = filters*2, strides = 2, activation=activation)\n    x = block(x, filters = filters*2, strides = 1, activation=activation)\n    x = block(x, filters = filters*4, strides = 2, activation=activation)\n    x = Dropout(0.2)(x)\n    x = block(x, filters = filters*4, strides = 1, activation=activation)\n    x = block(x, filters = filters*8, strides = 2, activation=activation)\n    for _ in range (reps):\n         x = block(x, filters = filters*8, strides = 1, activation=activation)\n    x = block(x, filters = filters*16, strides = 2, activation=activation)\n    x = block(x, filters = filters*16, strides = 1, activation=activation)\n    x = Dropout(0.2)(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = Flatten()(x)\n    output = Dense(units = 3, activation = 'softmax')(x)\n    model = Model(inputs=input, outputs=output)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet = MobileNet(input_shape=(256,256,3))\nmobilenet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nmobilenet_hist = mobilenet.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(mobilenet_hist.history)\nhist_json_file = 'MobileNet_10ep_histori.json'\nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = mobilenet.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(mobilenet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MobileNet v2","metadata":{}},{"cell_type":"code","source":"def inverted_residual_block(x, factor, filters_in, filters_out, strides, activation):\n    \n    x_add = x\n    x = Conv2D(filters=filters_in*factor, kernel_size=1, strides=1)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(activation)(x)\n    \n    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same')(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(activation)(x)\n    \n    x = Conv2D(filters=filters_out, kernel_size=1, strides=1,use_bias=False)(x)\n    x = BatchNormalization()(x)\n    \n    if x_add.shape[-1] == x.shape[-1]:\n        x = tf.keras.layers.Add()([x_add,x])\n    \n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MobileNet_v2(input_shape=(256,256,3)):\n    \n    input = Input(shape=input_shape)\n    \n    x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', use_bias=False)(input)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu6')(x)\n    \n    x = inverted_residual_block(x, factor=1, filters_in=x.shape[-1], filters_out=16, strides=1, activation='relu6')\n    x = Dropout(0.2)(x)\n    for i in range(2):\n        s = 1\n        if i == 0:\n            s = 2\n        x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=24, strides=s, activation='relu6')\n    for i in range(3):\n        s = 1\n        if i == 0:\n            s = 2\n        x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=32, strides=s, activation='relu6')\n    for i in range(4):\n        s = 1\n        if i == 0:\n            s = 2\n        x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=64, strides=s, activation='relu6')\n    for i in range(3):\n        x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=96, strides=1, activation='relu6')\n    for i in range(3):\n        s = 1\n        if i == 0:\n            s = 2\n        x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=160, strides=s, activation='relu6')\n    x = inverted_residual_block(x, factor=6, filters_in=x.shape[-1], filters_out=320, strides=1, activation='relu6')\n    x = Dropout(0.2)(x)\n    \n    x = Conv2D(filters=1280, kernel_size=1, padding='same', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu6')(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    \n    x = Flatten()(x)\n    output = Dense(units=3, activation='softmax')(x)\n    \n    model = Model(inputs=input, outputs=output)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_v2 = MobileNet_v2(input_shape=(256,256,3))\nmobilenet_v2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobilenet_v2.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nmobilenet_v2_hist = mobilenet_v2.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(mobilenet_v2_hist.history)\nhist_json_file = 'MobileNe_v2_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = mobilenet_v2.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(mobilenet_v2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MobileNet v3","metadata":{}},{"cell_type":"code","source":"def bottleneck_block(x, kernel_size, stride, filters_out, exp_size, SE, NL):\n\n    expanded_channels = exp_size\n    reduction_ratio = 4\n    x_add = x\n    \n    x = Conv2D(expanded_channels, kernel_size=1, padding='valid')(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(NL)(x)\n    \n    x = DepthwiseConv2D(kernel_size=kernel_size, padding='same', strides=stride)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(NL)(x)\n    \n    if SE == True:\n        # Squeeze and Excitation Layer\n        squeeze = tf.keras.layers.GlobalAveragePooling2D()(x)\n        excitation = Dense(expanded_channels // reduction_ratio, activation='relu')(squeeze)\n        excitation = Dense(expanded_channels, activation='hard_sigmoid')(excitation)\n        excitation = tf.keras.layers.Reshape((1, 1, expanded_channels))(excitation)\n        x = tf.keras.layers.multiply([x, excitation])\n\n    x = Conv2D(filters_out, kernel_size=1, padding='valid')(x)\n    x = BatchNormalization()(x)\n    \n    if x_add.shape == x.shape:\n        x = tf.keras.layers.add([x, x_add])\n    \n    return x\n\ndef efficient_final_layers(x,l=960):\n    x = Conv2D(l, kernel_size=1, padding='valid', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    \n    x = tf.keras.layers.AveragePooling2D(8)(x)\n    \n    x = Conv2D(1280, kernel_size=1, use_bias=False)(x)\n    x = tf.keras.layers.Activation('swish')(x)\n    x = Dropout(0.2)(x)\n    x = Conv2D(3, kernel_size=1, activation='softmax')(x)\n    \n    x = tf.squeeze(x, 1)\n    x = tf.squeeze(x, 1)\n    \n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def MobileNet_v3(size='Large',input_shape=(256,256,3)):\n    \n    input = Input(shape=input_shape)\n    \n    if size == 'Large':\n        x = Conv2D(16, kernel_size=3, padding='same', strides=2, use_bias=False)(input)\n        x = BatchNormalization()(x)\n        x = tf.keras.layers.Activation('swish')(x)\n\n                           # x  k  s  out exp sq&ex   act\n        x = bottleneck_block(x, 3, 1, 16, 16, False, 'relu')\n        x = bottleneck_block(x, 3, 2, 24, 64, False, 'relu')\n        x = bottleneck_block(x, 3, 1, 24, 72, False, 'relu')\n        x = Dropout(0.2)(x)\n\n        x = bottleneck_block(x, 5, 2, 40, 72, True, 'relu')\n        x = bottleneck_block(x, 5, 1, 40, 120, True, 'relu')\n        x = bottleneck_block(x, 5, 1, 40, 120, True, 'relu')\n\n        x = bottleneck_block(x, 3, 2, 80, 240, False, 'swish')\n        x = bottleneck_block(x, 3, 1, 80, 200, False, 'swish')\n        x = bottleneck_block(x, 3, 1, 80, 184, False, 'swish')\n        x = bottleneck_block(x, 3, 1, 80, 184, False, 'swish')\n        x = bottleneck_block(x, 3, 1, 112, 480, True, 'swish')\n        x = bottleneck_block(x, 3, 1, 112, 672, True, 'swish')\n        x = Dropout(0.2)(x)\n\n        x = bottleneck_block(x, 5, 2, 160, 672, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 160, 960, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 160, 960, True, 'swish')\n        \n\n        output = efficient_final_layers(x)\n\n        model = Model(inputs=input, outputs=output, name='MobileNetv3_large')\n    if size == 'Small':\n        x = Conv2D(16, kernel_size=3, padding='same', strides=2, use_bias=False)(input)\n        x = BatchNormalization()(x)\n        x = tf.keras.layers.Activation('swish')(x)\n\n                           # x  k  s  out exp sq&ex   act\n        x = bottleneck_block(x, 3, 2, 16, 16, True, 'relu')\n        x = bottleneck_block(x, 3, 2, 24, 72, False, 'relu')\n        x = bottleneck_block(x, 3, 1, 24, 88, False, 'relu')\n        x = Dropout(0.2)(x)\n        \n        x = bottleneck_block(x, 5, 2, 40, 96, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 40, 240, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 40, 240, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 48, 120, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 48, 144, True, 'swish')\n        x = bottleneck_block(x, 5, 2, 96, 288, True, 'swish')\n        x = Dropout(0.2)(x)\n        x = bottleneck_block(x, 5, 1, 96, 576, True, 'swish')\n        x = bottleneck_block(x, 5, 1, 96, 576, True, 'swish')\n\n        output = efficient_final_layers(x,l=576)\n\n        model = Model(inputs=input, outputs=output, name='MobileNetv3_Small')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Lmobilenet_v3 = MobileNet_v3(size='Large',input_shape=(256,256,3))\nLmobilenet_v3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Lmobilenet_v3.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nLmobilenet_v3_hist = Lmobilenet_v3.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(Lmobilenet_v3_hist.history)\nhist_json_file = 'LMobileNe_v3_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = Lmobilenet_v3.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(Lmobilenet_v3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Smobilenet_v3 = MobileNet_v3(size='Small',input_shape=(256,256,3))\nSmobilenet_v3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Smobilenet_v3.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nSmobilenet_v3_hist = Smobilenet_v3.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(Smobilenet_v3_hist.history)\nhist_json_file = 'SMobileNe_v3_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = Smobilenet_v3.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(Smobilenet_v3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet under 50","metadata":{}},{"cell_type":"code","source":"def identity_block(x, filter):\n    x_skip = x\n    \n    act = 'relu'\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization(axis=3)(x)\n    \n    x = tf.keras.layers.Add()([x, x_skip])\n    x = tf.keras.layers.Activation(act)(x)\n    \n    return x\n\ndef convolutional_block(x, filter):\n    x_skip = x\n    \n    act = 'relu'\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same', strides=2)(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization(axis=3)(x)\n    \n    x_skip = Conv2D(filters=filter, kernel_size=1, strides=2)(x_skip)\n    \n    x = tf.keras.layers.Add()([x, x_skip])\n    x = tf.keras.layers.Activation(act)(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ResNet(layers=18, input_shape=(256,256,3)):\n    \n    filters = 64\n    act = 'relu'\n    \n    input = Input(shape=input_shape)\n    #x = tf.keras.layers.ZeroPadding2D((3,3))(x_input)\n    \n    x = Conv2D(filters=filters, kernel_size=(7,7), strides=2)(input)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(act)(x)\n    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    \n    if layers == 18:\n        block_layers = [2,2,2,2]\n    if layers == 34:\n        block_layers = [3,4,6,3]\n    for i in range(4):\n        if i == 0:\n            for j in range(block_layers[i]):\n                x = identity_block(x, filters)\n        else:\n            filters = filters*2\n            x = convolutional_block(x, filters)\n            for j in range(block_layers[i] - 1):\n                x = identity_block(x, filters)\n    \n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    output = Dense(units=3, activation='softmax')(x)\n    \n    model = Model(inputs=input, outputs=output, name='ResNet18')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet18 = ResNet(input_shape=(256,256,3))\nresnet18.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet18.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nresnet18_hist = resnet18.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(resnet18_hist.history)\nhist_json_file = 'ResNet18_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = resnet18.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(resnet18)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet34 = ResNet(layers=34,input_shape=(256,256,3))\nresnet34.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet34.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nresnet34_hist = resnet34.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(resnet34_hist.history)\nhist_json_file = 'ResNet34_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = resnet34.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(resnet34)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet above 50","metadata":{}},{"cell_type":"code","source":"def BN_identity_block(x, filter):\n    x_skip = x\n    \n    act = 'relu'\n    \n    x = Conv2D(filters=filter, kernel_size=(1,1), padding='valid')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter*4, kernel_size=(1,1), padding='valid')(x)\n    x = BatchNormalization(axis=3)(x)\n    \n    x = tf.keras.layers.Add()([x, x_skip])\n    x = tf.keras.layers.Activation(act)(x)\n    \n    return x\n\ndef BN_convolutional_block(x, filter, s):\n    x_skip = x\n    \n    act = 'relu'\n    \n    x = Conv2D(filters=filter, kernel_size=(1,1), padding='valid', strides=s)(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter, kernel_size=(3,3), padding='same')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = tf.keras.layers.Activation(act)(x)\n    \n    x = Conv2D(filters=filter*4, kernel_size=(1,1), padding='valid')(x)\n    x = BatchNormalization(axis=3)(x)\n    \n    x_skip = Conv2D(filters=filter*4, kernel_size=1, strides=s, padding='valid')(x_skip)\n    \n    x = tf.keras.layers.Add()([x, x_skip])\n    x = tf.keras.layers.Activation(act)(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def BN_ResNet(input_shape=(256,256,3)):\n    \n    filters = 64\n    act = 'relu'\n    \n    x_input = Input(shape=input_shape)\n    \n    x = Conv2D(filters=filters, kernel_size=(7,7), strides=2)(x_input)\n    x = Dropout(0.2)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation(act)(x)\n    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n    \n    block_layers = [3,4,6,3]\n    for i in range(4):\n        if i == 0:\n            x = BN_convolutional_block(x=x, filter=filters, s=1)\n            for j in range(block_layers[i]-1):\n                x = BN_identity_block(x, filters)\n        else:\n            filters = filters*2\n            x = BN_convolutional_block(x, filters, s=2)\n            for j in range(block_layers[i] - 1):\n                x = BN_identity_block(x, filters)\n    \n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    output = Dense(units=3, activation='softmax')(x)\n    \n    model = Model(inputs=x_input, outputs=output, name='ResNet50')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50 = BN_ResNet(input_shape=(256,256,3))\nresnet50.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\nresnet50_hist = resnet50.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(resnet50_hist.history)\nhist_json_file = 'ResNet50_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = resnet50.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(resnet50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DenseNet","metadata":{}},{"cell_type":"code","source":"def convolutional_layer(x, filters, kernel=1, strides=1):\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = Conv2D(filters, kernel_size=kernel, strides=strides, padding='same')(x)\n    return x\n\ndef dense_block(x, layers, filters):\n    for _ in range(layers):\n        x_d = convolutional_layer(x, 4*filters)\n        x_d = convolutional_layer(x_d, filters, kernel=3)\n        x = tf.keras.layers.Concatenate()([x_d,x])\n    return x\n\ndef transition_layer(x):\n    x = convolutional_layer(x, filters=x.shape[-1]//2)\n    x = tf.keras.layers.AveragePooling2D(2, strides=2, padding='same')(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denseNet121(input_shape):\n    input = Input(shape=input_shape)\n    \n    x = Conv2D(filters=64, kernel_size=7, strides=2, padding='same')(input)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n    x = MaxPool2D(3, strides=2, padding='same')(x)\n    \n    for l in [6,12,24,16]:\n        d = dense_block(x, layers=l, filters=32)\n        x = Dropout(0.2)(x)\n        x = transition_layer(d)\n    x = Dropout(0.5)(x)\n        \n    x = tf.keras.layers.GlobalAveragePooling2D()(d)\n    x = Flatten()(x)\n    output = Dense(units=3, activation='softmax')(x)\n    \n    model = Model(inputs=input, outputs=output, name='DenseNet')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet = denseNet121(input_shape=(256,256,3))\ndensenet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"densenet.count_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\ndensenet_hist = densenet.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=10, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'10 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(densenet_hist.history)\nhist_json_file = 'densenet_10ep_histori.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = densenet.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(densenet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inception v1","metadata":{}},{"cell_type":"code","source":"def inception_module(x,filters_1x1,filters_3x3_reduce,filters_3x3,\n    filters_5x5_reduce,filters_5x5,filters_pool_proj,name=None):\n\n    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n\n    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(x)\n    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n    output = tf.keras.layers.Concatenate(axis=3, name=name)([conv_1x1, conv_3x3, conv_5x5, pool_proj])\n\n    return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inception_v1(input_shape=(256,256,3)):\n    \n    input = Input(shape=input_shape)\n    \n    x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2')(input)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n    x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n    x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n    \n    x = inception_module(x,filters_1x1=64,filters_3x3_reduce=96,\n     filters_3x3=128,filters_5x5_reduce=16,filters_5x5=32,filters_pool_proj=32,name='inception_3a')\n    x = Dropout(0.2)(x)\n    \n    x = inception_module(x,filters_1x1=128,filters_3x3_reduce=128,\n     filters_3x3=192,filters_5x5_reduce=32,filters_5x5=96,filters_pool_proj=64,name='inception_3b')\n    x = Dropout(0.2)(x)\n    \n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n    x = inception_module(x,filters_1x1=192,filters_3x3_reduce=96,\n    filters_3x3=208,filters_5x5_reduce=16,filters_5x5=48,filters_pool_proj=64, name='inception_4a')\n    x = Dropout(0.2)(x)\n    \n    x1 = tf.keras.layers.AveragePooling2D((5, 5), strides=3)(x)\n    x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n    x1 = Flatten()(x1)\n    x1 = Dense(1024, activation='relu')(x1)\n    x1 = Dropout(0.7)(x1)\n    x1 = Dense(3, activation='softmax', name='auxilliary_output_1')(x1)\n    \n    x = inception_module(x,filters_1x1=160,filters_3x3_reduce=112,\n    filters_3x3=224,filters_5x5_reduce=24,filters_5x5=64,filters_pool_proj=64,name='inception_4b')\n    x = Dropout(0.2)(x)\n    \n    x = inception_module(x,filters_1x1=128,filters_3x3_reduce=128,\n     filters_3x3=256,filters_5x5_reduce=24,filters_5x5=64,filters_pool_proj=64,name='inception_4c')\n    x = Dropout(0.2)(x)\n    \n    x = inception_module(x,filters_1x1=112,filters_3x3_reduce=144,\n     filters_3x3=288,filters_5x5_reduce=32,filters_5x5=64,filters_pool_proj=64,name='inception_4d')\n    x = Dropout(0.2)(x)\n    \n    x2 = tf.keras.layers.AveragePooling2D((5, 5), strides=3)(x)\n    x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n    x2 = Flatten()(x2)\n    x2 = Dense(1024, activation='relu')(x2)\n    x2 = Dropout(0.7)(x2)\n    x2 = Dense(3, activation='softmax', name='auxilliary_output_2')(x2)\n    \n    x = inception_module(x,filters_1x1=256,filters_3x3_reduce=160,\n     filters_3x3=320,filters_5x5_reduce=32,filters_5x5=128,filters_pool_proj=128,name='inception_4e')\n    \n    x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n    x = inception_module(x,filters_1x1=256,filters_3x3_reduce=160,\n     filters_3x3=320,filters_5x5_reduce=32,filters_5x5=128,filters_pool_proj=128,name='inception_5a')\n    \n    x = inception_module(x, filters_1x1=384,filters_3x3_reduce=192,\n     filters_3x3=384,filters_5x5_reduce=48,filters_5x5=128,filters_pool_proj=128,name='inception_5b')\n    \n    x = tf.keras.layers.GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n    x = Dropout(0.4)(x)\n    x = Dense(3, activation='softmax', name='output')(x)\n    \n    model = Model(inputs=input, outputs=[x, x1, x2], name='inception_v1')\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception1 = inception_v1(input_shape=(256,256,3))\ninception1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss=['categorical_crossentropy','categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1.0,0.3,0.3], metrics=[cat_acc,auc_roc,auc_pr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time()\ninception1_hist = inception1.fit(train_gen, steps_per_epoch=train_steps, \n                    validation_data=val_gen,\n                    validation_steps=val_steps,\n                    epochs=50, verbose=2)\nend = time()\nprint(\"===================================\")\nprint(f'50 epochs in {(end-start)/60} min')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception1.save_weights('Inception1.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_df = pd.DataFrame(inception1_hist.history)\nhist_json_file = 'inception1_10ep_history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = inception1.evaluate(test_gen)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_pred,label = test_gen.next()\ninception1.predict(to_pred), label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report(inception1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}